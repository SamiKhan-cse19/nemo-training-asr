{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"DATA/train_valid_without_errs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = df[\"transcripts\"].tolist()\n",
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DATA/train.txt\", \"w\") as f:\n",
    "    for transcript in transcripts:\n",
    "        if '\\t' in transcript:\n",
    "            f.write(transcript.split('\\t')[0].strip() + \"\\n\")\n",
    "        else:\n",
    "            f.write(transcript.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing text corpus (transcriptions of train dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banglanlptoolkit import BnNLPNormalizerPlus\n",
    "\n",
    "normalizer = BnNLPNormalizerPlus()\n",
    "res = normalizer(\"DATA/train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training text tokenizer with custom data and vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python process_asr_text_tokenizer.py --data_file=\"DATA/trainnormalized.txt\" \\\n",
    "    --data_root=\"tokenizer\" \\\n",
    "    --vocab_size=256 \\\n",
    "    --tokenizer=\"spe\" \\\n",
    "    --spe_type=\"bpe\" \\\n",
    "    --log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit manifest file to remove extra tabs and newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>6.300</td>\n",
       "      <td>আমি এই চেষ্টাটি একদমই করিনি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>8.420</td>\n",
       "      <td>এজন্য আগামীকাল ও মঙ্গলবার মুখ্যমন্ত্রীর দপ্তর ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>4.680</td>\n",
       "      <td>ফ্রোজেন ওয়াটার হতিছে যেটি পানি ঠান্ডায় জমে বরফ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/cv...</td>\n",
       "      <td>2.268</td>\n",
       "      <td>এই কাজের জন্য তিনি নোবেল পুরস্কার লাভ করেন।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/cv...</td>\n",
       "      <td>3.636</td>\n",
       "      <td>তিনি অটল দাঁড়িয়ে রইলেন যখন পরাজিতরা পালিয়ে গেল।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      audio_filepath  duration  \\\n",
       "0  /home/sami/workspace/nemo-asr-training/DATA/bn...     6.300   \n",
       "1  /home/sami/workspace/nemo-asr-training/DATA/bn...     8.420   \n",
       "2  /home/sami/workspace/nemo-asr-training/DATA/bn...     4.680   \n",
       "3  /home/sami/workspace/nemo-asr-training/DATA/cv...     2.268   \n",
       "4  /home/sami/workspace/nemo-asr-training/DATA/cv...     3.636   \n",
       "\n",
       "                                                text  \n",
       "0                        আমি এই চেষ্টাটি একদমই করিনি  \n",
       "1  এজন্য আগামীকাল ও মঙ্গলবার মুখ্যমন্ত্রীর দপ্তর ...  \n",
       "2  ফ্রোজেন ওয়াটার হতিছে যেটি পানি ঠান্ডায় জমে বরফ...  \n",
       "3        এই কাজের জন্য তিনি নোবেল পুরস্কার লাভ করেন।  \n",
       "4    তিনি অটল দাঁড়িয়ে রইলেন যখন পরাজিতরা পালিয়ে গেল।  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_manifest = pd.read_json(\"DATA/nemo_manifest.json\", lines=True, orient=\"records\")\n",
    "df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07200000000000001, 39.996)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manifest[\"duration\"].min(), df_manifest[\"duration\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_manifest[\"audio_filepath\"] = \"/home/sami/workspace/nemo-asr-training/DATA/\" + df_manifest[\"audio_filepath\"]\n",
    "# df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from banglanlptoolkit import BnNLPNormalizer\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# normalizer = BnNLPNormalizer(allow_en=True)\n",
    "# df_manifest[\"text\"] = df_manifest[\"text\"].progress_apply(normalizer.normalize_bn)\n",
    "# df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifest[\"text\"] = df_manifest[\"text\"].apply(lambda x: x.split(\"\\t\")[0].strip() if \"\\t\" in x else x.strip())\n",
    "df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifest.to_json(\"DATA/nemo_manifest.json\", lines=True, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Manifest into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(df_manifest, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_json(\"DATA/train_manifest.json\", lines=True, orient=\"records\", force_ascii=False)\n",
    "df_valid.to_json(\"DATA/valid_manifest.json\", lines=True, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Bucketing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python convert_to_tarred_audio_dataset.py \\\n",
    "        --manifest_path=DATA/train_manifest.json \\\n",
    "        --target_dir=DATA/train_bucket \\\n",
    "        --num_shards=128 \\\n",
    "        --max_duration=40 \\\n",
    "        --min_duration=0.1 \\\n",
    "        --shuffle \\\n",
    "        --shuffle_seed=1 \\\n",
    "        --sort_in_shards \\\n",
    "        --workers=24 \\\n",
    "        --buckets_num=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python speech_to_text_hybrid_rnnt_ctc_bpe.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
