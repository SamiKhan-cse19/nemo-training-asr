{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"DATA/train_valid_without_errs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = df[\"transcripts\"].tolist()\n",
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DATA/train.txt\", \"w\") as f:\n",
    "    for transcript in transcripts:\n",
    "        if '\\t' in transcript:\n",
    "            f.write(transcript.split('\\t')[0].strip() + \"\\n\")\n",
    "        else:\n",
    "            f.write(transcript.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing text corpus (transcriptions of train dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banglanlptoolkit import BnNLPNormalizerPlus\n",
    "\n",
    "normalizer = BnNLPNormalizerPlus()\n",
    "res = normalizer(\"DATA/train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training text tokenizer with custom data and vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python process_asr_text_tokenizer.py --data_file=\"DATA/trainnormalized.txt\" \\\n",
    "    --data_root=\"tokenizer\" \\\n",
    "    --vocab_size=256 \\\n",
    "    --tokenizer=\"spe\" \\\n",
    "    --spe_type=\"bpe\" \\\n",
    "    --log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit manifest file to remove extra tabs and newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>6.300</td>\n",
       "      <td>আমি এই চেষ্টাটি একদমই করিনি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>8.420</td>\n",
       "      <td>এজন্য আগামীকাল ও মঙ্গলবার মুখ্যমন্ত্রীর দপ্তর ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>4.680</td>\n",
       "      <td>ফ্রোজেন ওয়াটার হতিছে যেটি পানি ঠান্ডায় জমে বরফ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/cv...</td>\n",
       "      <td>2.268</td>\n",
       "      <td>এই কাজের জন্য তিনি নোবেল পুরস্কার লাভ করেন।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/cv...</td>\n",
       "      <td>3.636</td>\n",
       "      <td>তিনি অটল দাঁড়িয়ে রইলেন যখন পরাজিতরা পালিয়ে গেল।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      audio_filepath  duration  \\\n",
       "0  /home/sami/workspace/nemo-asr-training/DATA/bn...     6.300   \n",
       "1  /home/sami/workspace/nemo-asr-training/DATA/bn...     8.420   \n",
       "2  /home/sami/workspace/nemo-asr-training/DATA/bn...     4.680   \n",
       "3  /home/sami/workspace/nemo-asr-training/DATA/cv...     2.268   \n",
       "4  /home/sami/workspace/nemo-asr-training/DATA/cv...     3.636   \n",
       "\n",
       "                                                text  \n",
       "0                        আমি এই চেষ্টাটি একদমই করিনি  \n",
       "1  এজন্য আগামীকাল ও মঙ্গলবার মুখ্যমন্ত্রীর দপ্তর ...  \n",
       "2  ফ্রোজেন ওয়াটার হতিছে যেটি পানি ঠান্ডায় জমে বরফ...  \n",
       "3        এই কাজের জন্য তিনি নোবেল পুরস্কার লাভ করেন।  \n",
       "4    তিনি অটল দাঁড়িয়ে রইলেন যখন পরাজিতরা পালিয়ে গেল।  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_manifest = pd.read_json(\"DATA/nemo_manifest.json\", lines=True, orient=\"records\")\n",
    "df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filepath</th>\n",
       "      <th>duration</th>\n",
       "      <th>text</th>\n",
       "      <th>target_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>6.300</td>\n",
       "      <td>আমি এই চেষ্টাটি একদমই করিনি</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>8.420</td>\n",
       "      <td>এজন্য আগামীকাল ও মঙ্গলবার মুখ্যমন্ত্রীর দপ্তর ...</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/bn...</td>\n",
       "      <td>4.680</td>\n",
       "      <td>ফ্রোজেন ওয়াটার হতিছে যেটি পানি ঠান্ডায় জমে বরফ...</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/cv...</td>\n",
       "      <td>2.268</td>\n",
       "      <td>এই কাজের জন্য তিনি নোবেল পুরস্কার লাভ করেন।</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/sami/workspace/nemo-asr-training/DATA/cv...</td>\n",
       "      <td>3.636</td>\n",
       "      <td>তিনি অটল দাঁড়িয়ে রইলেন যখন পরাজিতরা পালিয়ে গেল।</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      audio_filepath  duration  \\\n",
       "0  /home/sami/workspace/nemo-asr-training/DATA/bn...     6.300   \n",
       "1  /home/sami/workspace/nemo-asr-training/DATA/bn...     8.420   \n",
       "2  /home/sami/workspace/nemo-asr-training/DATA/bn...     4.680   \n",
       "3  /home/sami/workspace/nemo-asr-training/DATA/cv...     2.268   \n",
       "4  /home/sami/workspace/nemo-asr-training/DATA/cv...     3.636   \n",
       "\n",
       "                                                text target_lang  \n",
       "0                        আমি এই চেষ্টাটি একদমই করিনি          bn  \n",
       "1  এজন্য আগামীকাল ও মঙ্গলবার মুখ্যমন্ত্রীর দপ্তর ...          bn  \n",
       "2  ফ্রোজেন ওয়াটার হতিছে যেটি পানি ঠান্ডায় জমে বরফ...          bn  \n",
       "3        এই কাজের জন্য তিনি নোবেল পুরস্কার লাভ করেন।          bn  \n",
       "4    তিনি অটল দাঁড়িয়ে রইলেন যখন পরাজিতরা পালিয়ে গেল।          bn  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manifest[\"target_lang\"] = \"bn\"\n",
    "df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07200000000000001, 39.996)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manifest[\"duration\"].min(), df_manifest[\"duration\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_manifest[\"audio_filepath\"] = \"/home/sami/workspace/nemo-asr-training/DATA/\" + df_manifest[\"audio_filepath\"]\n",
    "# df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from banglanlptoolkit import BnNLPNormalizer\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# normalizer = BnNLPNormalizer(allow_en=True)\n",
    "# df_manifest[\"text\"] = df_manifest[\"text\"].progress_apply(normalizer.normalize_bn)\n",
    "# df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifest[\"text\"] = df_manifest[\"text\"].apply(lambda x: x.split(\"\\t\")[0].strip() if \"\\t\" in x else x.strip())\n",
    "df_manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manifest.to_json(\"DATA/nemo_manifest.json\", lines=True, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Manifest into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_manifest = pd.read_json(\"DATA/nemo_manifest.json\", lines=True, orient=\"records\")\n",
    "\n",
    "df_manifest = df_manifest[df_manifest[\"duration\"] < 20.0]\n",
    "df_train, df_valid = train_test_split(df_manifest, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manifest[\"text\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_json(\"DATA/train_manifest.json\", lines=True, orient=\"records\", force_ascii=False)\n",
    "df_valid.to_json(\"DATA/valid_manifest.json\", lines=True, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Bucketing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python convert_to_tarred_audio_dataset.py \\\n",
    "        --manifest_path=DATA/train_manifest.json \\\n",
    "        --target_dir=DATA/train_bucket \\\n",
    "        --num_shards=128 \\\n",
    "        --max_duration=40 \\\n",
    "        --min_duration=0.1 \\\n",
    "        --shuffle \\\n",
    "        --shuffle_seed=1 \\\n",
    "        --sort_in_shards \\\n",
    "        --workers=24 \\\n",
    "        --buckets_num=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python speech_to_text_hybrid_rnnt_ctc_bpe.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "from nemo.utils import logging, exp_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:09:53 mixins:176] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:09:56 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: null\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    max_duration: 40\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    shard_manifests: true\n",
      "    use_lhotse: true\n",
      "    use_bucketing: true\n",
      "    num_buckets: 30\n",
      "    bucket_duration_bins: null\n",
      "    batch_duration: 600\n",
      "    defer_setup: true\n",
      "    \n",
      "[NeMo W 2025-03-13 15:09:56 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:09:56 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:09:57 nemo_logging:361] /home/sami/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:09:57 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
      "[NeMo I 2025-03-13 15:09:57 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:09:57 tdt_loop_labels_computer:281] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:09:57 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:09:57 tdt_loop_labels_computer:281] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:10:00 save_restore_connector:275] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/sami/.cache/huggingface/hub/models--nvidia--parakeet-tdt_ctc-110m/snapshots/431a349f3051ab85c22b9b7a2741b5fe77065665/parakeet-tdt_ctc-110m.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = nemo_asr.models.ASRModel.from_pretrained(\"nvidia/parakeet-tdt_ctc-110m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserve the decoder parameters in case weight matching can be done later\n",
    "pretrained_decoder = model.decoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:10:00 modelPT:281] You tried to register an artifact under config key=tokenizer.model_path but an artifact for it has already been registered.\n",
      "[NeMo W 2025-03-13 15:10:00 modelPT:281] You tried to register an artifact under config key=tokenizer.vocab_path but an artifact for it has already been registered.\n",
      "[NeMo W 2025-03-13 15:10:00 modelPT:281] You tried to register an artifact under config key=tokenizer.spe_tokenizer_vocab but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:10:00 mixins:176] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-03-13 15:10:01 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:10:01 tdt_loop_labels_computer:281] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:10:01 hybrid_rnnt_ctc_bpe_models:367] Changed tokenizer of the RNNT decoder to ['<unk>', '▁ক', 'য়', 'ার', '▁ব', '▁প', '▁স', 'ের', '্য', '্র', '▁আ', '▁এ', 'ান', '▁হ', '▁ম', '▁ত', '▁কর', '▁দ', '▁ন', '্ত', '▁জ', 'েন', '▁অ', 'কে', 'য়ে', 'তে', 'িন', '▁য', 'াল', '▁প্র', 'ছে', 'ায়', '▁গ', '▁র', 'িক', '▁শ', 'টি', 'বে', 'র্', '▁চ', 'লা', 'লে', '▁বি', 'ড়', 'াম', 'াক', '▁এক', '▁ভ', 'তি', '্ট', 'াজ', '▁উ', '্ব', '▁থ', '▁আম', 'িল', 'য়া', 'িত', '্যা', '▁নি', '▁পর', '▁বা', '▁করে', '্ষ', 'দের', 'াই', '▁কি', 'ুর', 'াস', '▁ও', '▁ফ', 'াত', 'ন্য', 'ন্', '▁দে', 'িনি', '▁সম', 'ুল', '▁খ', '▁ছ', 'নে', '▁যে', '্থ', '▁তা', 'টা', 'রা', '▁কো', '▁হয়', '▁ই', 'িয়ে', 'ির', '▁ট', 'ন্ত', 'াব', 'েকে', '▁না', '▁ল', '্প', 'ঙ্', 'েশ', '▁থেকে', 'ক্ষ', '▁তিনি', '▁সে', '▁করা', 'কার', '▁হয়ে', '▁ধ', 'চ্', '▁পা', '▁জন্য', '▁এব', 'িস', 'নের', '▁মা', 'বা', 'না', '▁এই', '▁পার', '▁এবং', 'াবে', 'েল', '▁ব্য', 'দ্', '্রী', '▁তার', 'িশ', 'ানে', 'ধ্য', 'রে', 'গে', 'ছেন', 'াকা', 'ার্', 'িতে', '▁সা', 'ক্ত', '▁দু', 'াষ', '▁সং', 'ওয়া', '▁পরি', '▁ড', 'ষ্', '▁কোন', 'স্থ', 'মা', '▁কা', 'বার', '▁উপ', 'বি', 'য়ার', 'িয়া', '▁আমি', 'োগ', 'দ্ধ', '▁রাজ', '▁ব্যা', '্রে', '▁আর', '▁ঘ', '▁অন', '▁জান', '▁করতে', '্ম', '▁বল', 'ুন', 'াগ', '্ন', '▁লা', 'ীর', 'দি', '▁ছিল', '▁হবে', 'ুম', 'জন', 'খন', 'তা', 'ীয়', '▁একটি', '▁করেন', 'ঞ্', '▁ব্যব', 'াপ', '▁সু', '▁হয়েছে', '▁সব', 'চ্ছে', '▁আমার', '▁আস', '▁নে', '▁বলে', '▁প্রতি', '্দ', '▁তো', 'ছিল', 'নি', '▁মু', 'ড়া', '▁যা', '▁সর', '▁টাকা', '▁বিশ', '্রি', '▁দেখ', 'স্ত', 'েষ', 'ভাবে', '▁চাষ', '▁এর', '▁অনে', 'াদ', 'কাল', '্স', 'ন্দ', 'র্ত', '▁নির্', 'াকে', 'হার', '▁কার', '▁যায়', '▁স্ব', '▁অব', '▁অনেক', 'দেশ', 'ৃত', 'ধান', 'োর', '▁বিভ', '▁মধ্য', 'গুল', '▁থাক', '▁কাজ', '্ড', 'কা', 'ভি', 'ছি', '▁দিয়ে', 'ঙ্গ', 'ষ্ঠ', '▁তাঁ', 'মে', '▁নিয়ে', 'ত্ত', 'থা', '্ল', '▁মে', 'ান্ত', 'টে', 'সে', '▁হচ্ছে', 'ুরু', 'াজার', 'মন', '▁মান', 'ছু', '▁রা', 'ন্ত্রী', 'লের', 'িম', '▁পে', '▁অনু', '▁রাজ্য', '▁বেশ', 'ড়ে', '▁সরকার', '▁আছে', '▁মধ্যে', '▁ভার', '▁গ্র', '▁আজ', 'ানা', 'োন', '▁কেন', 'হা', '্যাল', '▁দেশ', 'ারা', '▁কিছু', '▁কে', 'কের', 'িন্ন', 'রের', '▁কিন', 'রি', 'ষ্ট', '▁হই', 'মান', '▁বে', 'ঙ্গে', '▁ধর', 'াদের', '্যান', '▁সম্প', 'ক্র', 'গ্র', 'ূর্', 'ঞ্চ', '▁হিস', 'ুক্ত', 'ন্ট', '▁সময়', '▁নাম', '▁ভাল', 'িক্ষ', '▁দুই', '্ক', '▁ক্ষ', 'র্থ', '▁গে', 'খানে', '▁কম', 'িব', '▁করার', 'িং', '▁কত', 'ত্র', 'ংশ', '▁বিভিন্ন', 'মের', '▁জন', 'জে', '▁সঙ্গে', '▁কোনো', '▁গা', 'চিত', 'মন্ত্রী', '▁কী', 'থে', 'ডি', 'চার', 'ূল', 'াহ', 'ণের', 'পর', 'ওয়ার', '▁আপ', '▁অন্য', '▁সহ', 'ন্ধ', 'পুর', 'টির', 'াত্র', 'ঁচ', '▁আমরা', '▁আগ', '▁প্রধান', '্তু', 'ুষ', '▁গত', 'ানের', 'ীব', 'স্ট', '▁সাম', '▁তাদের', 'ল্প', '▁আমাদের', '▁কিন্তু', '▁রাখ', 'ড়ি', '▁খু', '▁পারে', '▁আল', 'জি', '▁কথা', 'য়ের', 'োল', '▁ভারত', '▁ভালো', 'ীন', 'েন্ট', '▁বাং', 'থম', 'ন্ত্র', 'োক', '▁পাওয়া', '▁বিশ্ব', '▁তিন', '▁রয়ে', '▁ছিলেন', 'স্য', 'তির', 'ালে', '▁চল', '▁দি', '▁হল', 'োট', 'েবে', 'প্ত', 'দিন', '▁রক', '▁গু', 'স্থা', 'েত', 'জ্', '▁এখন', '▁সি', '▁কৃ', 'সা', '▁মুখ', '▁দিন', '▁একটা', '▁থাকে', 'ারে', 'যোগ', '▁মহ', '▁মানুষ', 'তো', 'নার', '▁স্থ', 'মার', 'ছিলেন', 'ুক', 'াড়া', '▁বাংলা', 'ন্ন', '▁বছ', '▁রে', '▁হিসেবে', '▁শুরু', '▁শিক্ষ', 'র্ব', 'ঙ্ক', 'িকা', '্যে', 'পি', 'লাম', '▁সাথে', 'ধার', '▁রয়েছে', '▁কেন্দ', '▁তাকে', '▁অধ', 'িয়', '▁পর্য', 'টার', '▁হাজার', '▁প্রথম', 'বাদ', '▁জম', '▁কর্ম', '▁ঠ', '▁অভি', 'ামী', 'েলা', '▁কৃষ', 'োধ', 'ানো', 'দা', '▁এটি', '▁বিষ', '▁সেই', '▁বেশি', 'ণে', '▁ব্যবহার', '▁আই', '▁মাধ্য', '▁দেওয়া', 'লাই', 'ার্ড', 'তিছে', '▁পাল', 'াতে', 'াউ', 'সব', 'জ্ঞ', '▁বৃ', '▁ব্যাং', 'ঞ্জ', 'িকার', '▁ধরনের', '▁তাঁর', '▁করব', 'শি', 'শন', '▁গতকাল', '▁বী', '▁মাস', 'ুদ্ধ', '▁যেটা', 'ত্যা', 'শ্', 'াঁ', '▁করেছেন', '▁হলে', 'চে', '▁পুর', '▁শু', 'বর্ত', 'প্র', 'ানি', '▁তবে', '▁প্রক', '▁চাল', '▁কল', 'ীদের', '▁দিতে', '▁রকমের', '▁অর্থ', '▁পুল', '▁অনুষ্ঠ', '▁চার', 'ুত', '▁করেছে', 'ুমি', 'ভাব', '▁টি', '▁শেষ', '▁তারা', 'াট', '▁পারি', 'কাশ', 'গুলো', '▁নির্বা', '▁লাগ', '▁চে', '▁তুমি', '▁ফস', '▁আব', 'দ্র', '▁ঋ', 'জের', '▁একজন', '্লা', '▁বাংলাদেশ', '▁জীব', 'সের', '▁দ্ব', '▁মি', '▁নত', '▁কিভাবে', '▁স্ট', '▁পুলিশ', 'ক্তি', '▁জল', '▁কাছে', '▁নতুন', 'ীত', 'রণ', '▁উত্ত', '▁মানে', 'দ্য', 'ত্য', 'ত্ব', '▁মাধ্যমে', '▁মনে', '▁অংশ', 'ম্ব', '▁লে', 'ন্ড', 'াতা', '▁ইউ', 'ার্থ', '▁পু', '▁ডি', '▁লি', 'েলার', '▁হতে', '▁ফল', '▁খুব', '▁বলেন', '▁যদি', '▁পাঠ', 'ক্ষে', '▁আগে', 'ণা', '▁অবস্থ', '▁হাস', '▁বাড়', 'র্ষ', '▁তৈ', '▁এলা', 'সি', 'খে', '▁ঢ', '▁যাবে', 'চ্চ', '▁পরে', '▁নয়', '▁ট্র', '▁প্রা', '▁পর্যন্ত', 'নী', '▁মূল', '▁বন্ধ', '▁বু', 'জা', 'তিক', '▁প্রশ', '▁মো', '▁প্রয়', '▁জাত', 'তার', '▁পাঁচ', '▁জানিয়ে', '▁বৈ', 'ুই', '▁বিশেষ', 'ূর্ণ', '▁সর্ব', 'াবার', '▁লক্ষ', '▁শহ', '▁উৎ', '▁হার', 'র্ম', 'হণ', 'ষ্টি', '▁ঠিক', '▁সভ', '▁এসে', 'ক্ষা', 'ধা', '▁এটা', '▁করি', 'দ্যাল', '▁গিয়ে', '▁গুল', '▁সদ', 'দী', 'সভ', '▁উদ্', '▁দেখা', '▁বার', 'পাত', '▁তোমার', 'াধ', 'ূন্য', 'সম', '▁ঘট', '▁নেই', '▁জেলা', '▁নির্বাচ', '▁দেশের', '▁বাজার', '▁নিয়', 'শ্চ', 'োপ', '▁বছর', 'ারি', '▁ব্যাঙ্ক', 'স্', '▁ব্যবস্থা', 'াস্থ', '▁ঝ', '▁কার্ড', 'চ্ছ', 'দন', '্যাক', '▁উপর', 'কেট', '▁মুখ্য', '্টা', '্লে', '▁পরিচ', '▁আগামী', '▁গেছে', '▁বির', 'গুলি', '▁অপ', '▁পড়', 'চনা', '▁চাষের', '▁স্ক', '▁দেব', 'োজন', '▁দশ', '▁আট', 'মিক', 'দে', '▁আশ', 'াকার', '▁শিল', '্যের', 'েত্রে', '▁পদ্ধ', '▁শূন্য', 'ুলে', '▁মৃত', 'িজ', '▁প্রধানমন্ত্রী', '▁এমন', '▁সার', 'য়েক', '▁একাউ', '▁শো', 'ওয়', 'সার', '▁আয়', 'লার', '▁আমাকে', '▁পড়ে', 'োজ', '▁সেটা', 'ূপ', 'বর', '▁মন', '▁উল', '▁মার্', '▁লোন', '▁ব্যাপ', '▁পো', '▁চাই', 'মাণ', '▁যেমন', '▁কয়েক', '▁লোক', '▁পূর্', 'ধারণ', '▁বড়', '▁বর্ত', '▁মতো', '▁হন', '▁গুরু', '▁গাছ', '▁ঐ', '▁তখন', 'দান', '▁চলে', '▁একাউন্ট', 'ুট', '▁লাভ', '▁উন্ন', 'ংস', '▁যখন', 'যুক্ত', '▁উত্তর', 'াড়', '▁গুলা', '▁জিনি', '▁পদ্ধতি', 'খ্যা', 'িত্ব', 'কি', '▁পি', '▁জাতীয়', '▁এখানে', '▁দল', '▁পাশ', '▁ঋণ', 'বল', '▁বাই', '▁তাই', 'েন্স', '▁ধার', 'ছাড়া', '▁ছে', '▁প্রকাশ', '▁রাজ্যের', '▁বিষয়', 'ঠে', 'েন্দ', '▁পাই', '▁ভাবে', '্যান্ড', '▁দায়', '▁প্রত', 'দিকে', '▁প্রতিষ্ঠ', '▁গ্রাম', '▁যোগ', '্ভ', 'বাস', 'র্শ', '▁কলে', '▁হতিছে', '▁দক্ষ', 'টের', '▁বিক', '▁পারব', 'গর', '▁ছোট', 'তম', 'ালা', 'রকার', '▁অস', 'িলা', '▁বান', '্রীয়', '▁জানান', 'বেশ', '▁আন', '▁দিকে', '▁ব্যাংক', '্যাপ', '▁স্বাস্থ', '▁অনলাই', 'য়ন', '▁হাসপাত', '▁প্রকল্প', '▁সুবি', 'ণ্ড', 'েই', '▁ক্ষেত্রে', '▁অর্', '▁মাটি', '▁মুখ্যমন্ত্রী', '▁ক্য', '▁সম্পর্', '▁কৃষি', '▁যেতে', '▁ভাই', '▁সূ', 'িতা', 'ীতে', 'ভে', 'ম্প', '▁জায়', '▁বলা', '▁গেলে', '▁পাব', '▁করলে', '▁চিক', 'নায়', '▁কেন্দ্র', '▁হয়েছিল', 'গত', '▁ভাষ', 'যাগ', 'বেদন', 'লেন', '▁ফসল', 'ক্রম', '▁মাল', '▁আহ', '▁ইত্যা', '▁ডে', '▁ধরে', '▁পেতে', '▁জায়গ', '▁গো', '▁ভূ', 'ধু', 'ায়ের', '▁ফুল', '▁সাত', '▁পদ', '▁আবার', '▁সেখানে', '▁পরিচাল', '▁ক্রি', '▁জমিতে', 'আই', '▁স্বাস্থ্য', '▁অভ', 'বাহ', '▁ফে', '▁ফির', 'িপ', '▁বো', '▁দেন', '▁সদস্য', 'ষে', '▁দেয়', '▁আলা', 'থায়', '▁পরী', 'ায়ী', 'ৈতিক', 'িন্দ', '▁কাল', '▁এছাড়া', '▁আদ', '▁আরও', '▁শ্রী', '▁পালন', 'নিক', 'ন্তর্', '▁স্প', '▁অঞ্চ', '▁কেন্দ্রীয়', 'ান্য', '▁পেয়ে', '▁ইত্যাদি', '▁তৈরি', '▁মৃত্য', '▁পশ্চ', '▁জেলার', '▁সম্ম', '▁যুক্ত', '▁ভে', 'মেন্ট', '▁হাই', 'শী', '▁সাধারণ', '▁কার্য', '▁মত', '▁নিজের', 'ুব', '▁লো', '্লেখ', '▁বহ', '▁বুঝ', 'ালের', '▁জন্যে', '▁উল্লেখ', 'ুদ্ধে', 'ৃতি', '▁বাহ', 'ীরা', 'ংগ', 'শু', '▁দেশে', 'ারের', '▁দলের', '▁বীজ', 'েন্দ্র', 'চিত্র', '▁নাই', '▁অফ', '▁গুরুত্ব', '▁কুম', 'কর', '▁পৌ', '▁বিল', 'নৈতিক', '▁স্থান', '▁আধ', '▁কারণে', '▁পরিবার', '▁শস্য', '▁উৎপ', 'াবি', 'বিদ্যাল', '▁ছাড়া', 'খান', '▁সাহা', 'াস্ত', '্যার', '▁সকাল', 'াক্ত', 'মু', '▁শে', '▁বিপ', '্টি', 'িট', '▁', 'া', 'ে', 'র', '্', 'ি', 'ন', 'ক', 'য', 'ব', 'ত', 'ল', 'ম', 'স', 'প', '়', 'দ', 'ু', 'ট', 'হ', 'জ', 'ো', 'শ', 'গ', 'ছ', 'আ', 'এ', 'ই', 'চ', 'ী', '।', 'ষ', 'ভ', 'থ', 'ধ', 'ড', 'খ', 'অ', 'ও', 'ং', 'উ', 'ণ', 'ফ', ',', 'ূ', 'ঠ', 'ৃ', 'ঁ', 'ঙ', 'ঘ', 'ঞ', '-', 'ৈ', '?', 'ৌ', 'ৎ', 'ঝ', '.', '!', 'ঢ', 'ঋ', '\"', 'ঃ', 'ঐ', '১', 'ঊ', '০', \"'\", '২', 'ঈ', '৯', '৫', '৩', '৮', '৪', '৭', '৬', 'ঔ', ':', '—', '=', ';', '\\u200d', '(', ')', '”', '[', ']'] vocabulary.\n",
      "[NeMo I 2025-03-13 15:10:01 hybrid_rnnt_ctc_bpe_models:380] \n",
      "    Replacing old number of classes (1024) with new number of classes - 1024\n",
      "[NeMo I 2025-03-13 15:10:01 hybrid_rnnt_ctc_bpe_models:421] Changed tokenizer of the CTC decoder to ['<unk>', '▁ক', 'য়', 'ার', '▁ব', '▁প', '▁স', 'ের', '্য', '্র', '▁আ', '▁এ', 'ান', '▁হ', '▁ম', '▁ত', '▁কর', '▁দ', '▁ন', '্ত', '▁জ', 'েন', '▁অ', 'কে', 'য়ে', 'তে', 'িন', '▁য', 'াল', '▁প্র', 'ছে', 'ায়', '▁গ', '▁র', 'িক', '▁শ', 'টি', 'বে', 'র্', '▁চ', 'লা', 'লে', '▁বি', 'ড়', 'াম', 'াক', '▁এক', '▁ভ', 'তি', '্ট', 'াজ', '▁উ', '্ব', '▁থ', '▁আম', 'িল', 'য়া', 'িত', '্যা', '▁নি', '▁পর', '▁বা', '▁করে', '্ষ', 'দের', 'াই', '▁কি', 'ুর', 'াস', '▁ও', '▁ফ', 'াত', 'ন্য', 'ন্', '▁দে', 'িনি', '▁সম', 'ুল', '▁খ', '▁ছ', 'নে', '▁যে', '্থ', '▁তা', 'টা', 'রা', '▁কো', '▁হয়', '▁ই', 'িয়ে', 'ির', '▁ট', 'ন্ত', 'াব', 'েকে', '▁না', '▁ল', '্প', 'ঙ্', 'েশ', '▁থেকে', 'ক্ষ', '▁তিনি', '▁সে', '▁করা', 'কার', '▁হয়ে', '▁ধ', 'চ্', '▁পা', '▁জন্য', '▁এব', 'িস', 'নের', '▁মা', 'বা', 'না', '▁এই', '▁পার', '▁এবং', 'াবে', 'েল', '▁ব্য', 'দ্', '্রী', '▁তার', 'িশ', 'ানে', 'ধ্য', 'রে', 'গে', 'ছেন', 'াকা', 'ার্', 'িতে', '▁সা', 'ক্ত', '▁দু', 'াষ', '▁সং', 'ওয়া', '▁পরি', '▁ড', 'ষ্', '▁কোন', 'স্থ', 'মা', '▁কা', 'বার', '▁উপ', 'বি', 'য়ার', 'িয়া', '▁আমি', 'োগ', 'দ্ধ', '▁রাজ', '▁ব্যা', '্রে', '▁আর', '▁ঘ', '▁অন', '▁জান', '▁করতে', '্ম', '▁বল', 'ুন', 'াগ', '্ন', '▁লা', 'ীর', 'দি', '▁ছিল', '▁হবে', 'ুম', 'জন', 'খন', 'তা', 'ীয়', '▁একটি', '▁করেন', 'ঞ্', '▁ব্যব', 'াপ', '▁সু', '▁হয়েছে', '▁সব', 'চ্ছে', '▁আমার', '▁আস', '▁নে', '▁বলে', '▁প্রতি', '্দ', '▁তো', 'ছিল', 'নি', '▁মু', 'ড়া', '▁যা', '▁সর', '▁টাকা', '▁বিশ', '্রি', '▁দেখ', 'স্ত', 'েষ', 'ভাবে', '▁চাষ', '▁এর', '▁অনে', 'াদ', 'কাল', '্স', 'ন্দ', 'র্ত', '▁নির্', 'াকে', 'হার', '▁কার', '▁যায়', '▁স্ব', '▁অব', '▁অনেক', 'দেশ', 'ৃত', 'ধান', 'োর', '▁বিভ', '▁মধ্য', 'গুল', '▁থাক', '▁কাজ', '্ড', 'কা', 'ভি', 'ছি', '▁দিয়ে', 'ঙ্গ', 'ষ্ঠ', '▁তাঁ', 'মে', '▁নিয়ে', 'ত্ত', 'থা', '্ল', '▁মে', 'ান্ত', 'টে', 'সে', '▁হচ্ছে', 'ুরু', 'াজার', 'মন', '▁মান', 'ছু', '▁রা', 'ন্ত্রী', 'লের', 'িম', '▁পে', '▁অনু', '▁রাজ্য', '▁বেশ', 'ড়ে', '▁সরকার', '▁আছে', '▁মধ্যে', '▁ভার', '▁গ্র', '▁আজ', 'ানা', 'োন', '▁কেন', 'হা', '্যাল', '▁দেশ', 'ারা', '▁কিছু', '▁কে', 'কের', 'িন্ন', 'রের', '▁কিন', 'রি', 'ষ্ট', '▁হই', 'মান', '▁বে', 'ঙ্গে', '▁ধর', 'াদের', '্যান', '▁সম্প', 'ক্র', 'গ্র', 'ূর্', 'ঞ্চ', '▁হিস', 'ুক্ত', 'ন্ট', '▁সময়', '▁নাম', '▁ভাল', 'িক্ষ', '▁দুই', '্ক', '▁ক্ষ', 'র্থ', '▁গে', 'খানে', '▁কম', 'িব', '▁করার', 'িং', '▁কত', 'ত্র', 'ংশ', '▁বিভিন্ন', 'মের', '▁জন', 'জে', '▁সঙ্গে', '▁কোনো', '▁গা', 'চিত', 'মন্ত্রী', '▁কী', 'থে', 'ডি', 'চার', 'ূল', 'াহ', 'ণের', 'পর', 'ওয়ার', '▁আপ', '▁অন্য', '▁সহ', 'ন্ধ', 'পুর', 'টির', 'াত্র', 'ঁচ', '▁আমরা', '▁আগ', '▁প্রধান', '্তু', 'ুষ', '▁গত', 'ানের', 'ীব', 'স্ট', '▁সাম', '▁তাদের', 'ল্প', '▁আমাদের', '▁কিন্তু', '▁রাখ', 'ড়ি', '▁খু', '▁পারে', '▁আল', 'জি', '▁কথা', 'য়ের', 'োল', '▁ভারত', '▁ভালো', 'ীন', 'েন্ট', '▁বাং', 'থম', 'ন্ত্র', 'োক', '▁পাওয়া', '▁বিশ্ব', '▁তিন', '▁রয়ে', '▁ছিলেন', 'স্য', 'তির', 'ালে', '▁চল', '▁দি', '▁হল', 'োট', 'েবে', 'প্ত', 'দিন', '▁রক', '▁গু', 'স্থা', 'েত', 'জ্', '▁এখন', '▁সি', '▁কৃ', 'সা', '▁মুখ', '▁দিন', '▁একটা', '▁থাকে', 'ারে', 'যোগ', '▁মহ', '▁মানুষ', 'তো', 'নার', '▁স্থ', 'মার', 'ছিলেন', 'ুক', 'াড়া', '▁বাংলা', 'ন্ন', '▁বছ', '▁রে', '▁হিসেবে', '▁শুরু', '▁শিক্ষ', 'র্ব', 'ঙ্ক', 'িকা', '্যে', 'পি', 'লাম', '▁সাথে', 'ধার', '▁রয়েছে', '▁কেন্দ', '▁তাকে', '▁অধ', 'িয়', '▁পর্য', 'টার', '▁হাজার', '▁প্রথম', 'বাদ', '▁জম', '▁কর্ম', '▁ঠ', '▁অভি', 'ামী', 'েলা', '▁কৃষ', 'োধ', 'ানো', 'দা', '▁এটি', '▁বিষ', '▁সেই', '▁বেশি', 'ণে', '▁ব্যবহার', '▁আই', '▁মাধ্য', '▁দেওয়া', 'লাই', 'ার্ড', 'তিছে', '▁পাল', 'াতে', 'াউ', 'সব', 'জ্ঞ', '▁বৃ', '▁ব্যাং', 'ঞ্জ', 'িকার', '▁ধরনের', '▁তাঁর', '▁করব', 'শি', 'শন', '▁গতকাল', '▁বী', '▁মাস', 'ুদ্ধ', '▁যেটা', 'ত্যা', 'শ্', 'াঁ', '▁করেছেন', '▁হলে', 'চে', '▁পুর', '▁শু', 'বর্ত', 'প্র', 'ানি', '▁তবে', '▁প্রক', '▁চাল', '▁কল', 'ীদের', '▁দিতে', '▁রকমের', '▁অর্থ', '▁পুল', '▁অনুষ্ঠ', '▁চার', 'ুত', '▁করেছে', 'ুমি', 'ভাব', '▁টি', '▁শেষ', '▁তারা', 'াট', '▁পারি', 'কাশ', 'গুলো', '▁নির্বা', '▁লাগ', '▁চে', '▁তুমি', '▁ফস', '▁আব', 'দ্র', '▁ঋ', 'জের', '▁একজন', '্লা', '▁বাংলাদেশ', '▁জীব', 'সের', '▁দ্ব', '▁মি', '▁নত', '▁কিভাবে', '▁স্ট', '▁পুলিশ', 'ক্তি', '▁জল', '▁কাছে', '▁নতুন', 'ীত', 'রণ', '▁উত্ত', '▁মানে', 'দ্য', 'ত্য', 'ত্ব', '▁মাধ্যমে', '▁মনে', '▁অংশ', 'ম্ব', '▁লে', 'ন্ড', 'াতা', '▁ইউ', 'ার্থ', '▁পু', '▁ডি', '▁লি', 'েলার', '▁হতে', '▁ফল', '▁খুব', '▁বলেন', '▁যদি', '▁পাঠ', 'ক্ষে', '▁আগে', 'ণা', '▁অবস্থ', '▁হাস', '▁বাড়', 'র্ষ', '▁তৈ', '▁এলা', 'সি', 'খে', '▁ঢ', '▁যাবে', 'চ্চ', '▁পরে', '▁নয়', '▁ট্র', '▁প্রা', '▁পর্যন্ত', 'নী', '▁মূল', '▁বন্ধ', '▁বু', 'জা', 'তিক', '▁প্রশ', '▁মো', '▁প্রয়', '▁জাত', 'তার', '▁পাঁচ', '▁জানিয়ে', '▁বৈ', 'ুই', '▁বিশেষ', 'ূর্ণ', '▁সর্ব', 'াবার', '▁লক্ষ', '▁শহ', '▁উৎ', '▁হার', 'র্ম', 'হণ', 'ষ্টি', '▁ঠিক', '▁সভ', '▁এসে', 'ক্ষা', 'ধা', '▁এটা', '▁করি', 'দ্যাল', '▁গিয়ে', '▁গুল', '▁সদ', 'দী', 'সভ', '▁উদ্', '▁দেখা', '▁বার', 'পাত', '▁তোমার', 'াধ', 'ূন্য', 'সম', '▁ঘট', '▁নেই', '▁জেলা', '▁নির্বাচ', '▁দেশের', '▁বাজার', '▁নিয়', 'শ্চ', 'োপ', '▁বছর', 'ারি', '▁ব্যাঙ্ক', 'স্', '▁ব্যবস্থা', 'াস্থ', '▁ঝ', '▁কার্ড', 'চ্ছ', 'দন', '্যাক', '▁উপর', 'কেট', '▁মুখ্য', '্টা', '্লে', '▁পরিচ', '▁আগামী', '▁গেছে', '▁বির', 'গুলি', '▁অপ', '▁পড়', 'চনা', '▁চাষের', '▁স্ক', '▁দেব', 'োজন', '▁দশ', '▁আট', 'মিক', 'দে', '▁আশ', 'াকার', '▁শিল', '্যের', 'েত্রে', '▁পদ্ধ', '▁শূন্য', 'ুলে', '▁মৃত', 'িজ', '▁প্রধানমন্ত্রী', '▁এমন', '▁সার', 'য়েক', '▁একাউ', '▁শো', 'ওয়', 'সার', '▁আয়', 'লার', '▁আমাকে', '▁পড়ে', 'োজ', '▁সেটা', 'ূপ', 'বর', '▁মন', '▁উল', '▁মার্', '▁লোন', '▁ব্যাপ', '▁পো', '▁চাই', 'মাণ', '▁যেমন', '▁কয়েক', '▁লোক', '▁পূর্', 'ধারণ', '▁বড়', '▁বর্ত', '▁মতো', '▁হন', '▁গুরু', '▁গাছ', '▁ঐ', '▁তখন', 'দান', '▁চলে', '▁একাউন্ট', 'ুট', '▁লাভ', '▁উন্ন', 'ংস', '▁যখন', 'যুক্ত', '▁উত্তর', 'াড়', '▁গুলা', '▁জিনি', '▁পদ্ধতি', 'খ্যা', 'িত্ব', 'কি', '▁পি', '▁জাতীয়', '▁এখানে', '▁দল', '▁পাশ', '▁ঋণ', 'বল', '▁বাই', '▁তাই', 'েন্স', '▁ধার', 'ছাড়া', '▁ছে', '▁প্রকাশ', '▁রাজ্যের', '▁বিষয়', 'ঠে', 'েন্দ', '▁পাই', '▁ভাবে', '্যান্ড', '▁দায়', '▁প্রত', 'দিকে', '▁প্রতিষ্ঠ', '▁গ্রাম', '▁যোগ', '্ভ', 'বাস', 'র্শ', '▁কলে', '▁হতিছে', '▁দক্ষ', 'টের', '▁বিক', '▁পারব', 'গর', '▁ছোট', 'তম', 'ালা', 'রকার', '▁অস', 'িলা', '▁বান', '্রীয়', '▁জানান', 'বেশ', '▁আন', '▁দিকে', '▁ব্যাংক', '্যাপ', '▁স্বাস্থ', '▁অনলাই', 'য়ন', '▁হাসপাত', '▁প্রকল্প', '▁সুবি', 'ণ্ড', 'েই', '▁ক্ষেত্রে', '▁অর্', '▁মাটি', '▁মুখ্যমন্ত্রী', '▁ক্য', '▁সম্পর্', '▁কৃষি', '▁যেতে', '▁ভাই', '▁সূ', 'িতা', 'ীতে', 'ভে', 'ম্প', '▁জায়', '▁বলা', '▁গেলে', '▁পাব', '▁করলে', '▁চিক', 'নায়', '▁কেন্দ্র', '▁হয়েছিল', 'গত', '▁ভাষ', 'যাগ', 'বেদন', 'লেন', '▁ফসল', 'ক্রম', '▁মাল', '▁আহ', '▁ইত্যা', '▁ডে', '▁ধরে', '▁পেতে', '▁জায়গ', '▁গো', '▁ভূ', 'ধু', 'ায়ের', '▁ফুল', '▁সাত', '▁পদ', '▁আবার', '▁সেখানে', '▁পরিচাল', '▁ক্রি', '▁জমিতে', 'আই', '▁স্বাস্থ্য', '▁অভ', 'বাহ', '▁ফে', '▁ফির', 'িপ', '▁বো', '▁দেন', '▁সদস্য', 'ষে', '▁দেয়', '▁আলা', 'থায়', '▁পরী', 'ায়ী', 'ৈতিক', 'িন্দ', '▁কাল', '▁এছাড়া', '▁আদ', '▁আরও', '▁শ্রী', '▁পালন', 'নিক', 'ন্তর্', '▁স্প', '▁অঞ্চ', '▁কেন্দ্রীয়', 'ান্য', '▁পেয়ে', '▁ইত্যাদি', '▁তৈরি', '▁মৃত্য', '▁পশ্চ', '▁জেলার', '▁সম্ম', '▁যুক্ত', '▁ভে', 'মেন্ট', '▁হাই', 'শী', '▁সাধারণ', '▁কার্য', '▁মত', '▁নিজের', 'ুব', '▁লো', '্লেখ', '▁বহ', '▁বুঝ', 'ালের', '▁জন্যে', '▁উল্লেখ', 'ুদ্ধে', 'ৃতি', '▁বাহ', 'ীরা', 'ংগ', 'শু', '▁দেশে', 'ারের', '▁দলের', '▁বীজ', 'েন্দ্র', 'চিত্র', '▁নাই', '▁অফ', '▁গুরুত্ব', '▁কুম', 'কর', '▁পৌ', '▁বিল', 'নৈতিক', '▁স্থান', '▁আধ', '▁কারণে', '▁পরিবার', '▁শস্য', '▁উৎপ', 'াবি', 'বিদ্যাল', '▁ছাড়া', 'খান', '▁সাহা', 'াস্ত', '্যার', '▁সকাল', 'াক্ত', 'মু', '▁শে', '▁বিপ', '্টি', 'িট', '▁', 'া', 'ে', 'র', '্', 'ি', 'ন', 'ক', 'য', 'ব', 'ত', 'ল', 'ম', 'স', 'প', '়', 'দ', 'ু', 'ট', 'হ', 'জ', 'ো', 'শ', 'গ', 'ছ', 'আ', 'এ', 'ই', 'চ', 'ী', '।', 'ষ', 'ভ', 'থ', 'ধ', 'ড', 'খ', 'অ', 'ও', 'ং', 'উ', 'ণ', 'ফ', ',', 'ূ', 'ঠ', 'ৃ', 'ঁ', 'ঙ', 'ঘ', 'ঞ', '-', 'ৈ', '?', 'ৌ', 'ৎ', 'ঝ', '.', '!', 'ঢ', 'ঋ', '\"', 'ঃ', 'ঐ', '১', 'ঊ', '০', \"'\", '২', 'ঈ', '৯', '৫', '৩', '৮', '৪', '৭', '৬', 'ঔ', ':', '—', '=', ';', '\\u200d', '(', ')', '”', '[', ']'] vocabulary.\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER_DIR = \"tokenizer/tokenizer_spe_bpe_v1024\"\n",
    "model.change_vocabulary(new_tokenizer_dir=TOKENIZER_DIR, new_tokenizer_type=\"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNTDecoder(\n",
       "  (prediction): ModuleDict(\n",
       "    (embed): Embedding(1025, 640, padding_idx=1024)\n",
       "    (dec_rnn): LSTMDropout(\n",
       "      (lstm): LSTM(640, 640, dropout=0.2)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def enable_bn_se(m):\n",
    "    if type(m) == nn.BatchNorm1d:\n",
    "        m.train()\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad_(True)\n",
    "\n",
    "    if 'SqueezeExcite' in type(m).__name__:\n",
    "        m.train()\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:10:01 3588566142:6] Model encoder has been frozen\n"
     ]
    }
   ],
   "source": [
    "freeze_encoder = True\n",
    "\n",
    "if freeze_encoder:\n",
    "  model.encoder.freeze()\n",
    "  model.encoder.apply(enable_bn_se)\n",
    "  logging.info(\"Model encoder has been frozen\")\n",
    "else:\n",
    "  model.encoder.unfreeze()\n",
    "  logging.info(\"Model encoder has been un-frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "cfg = copy.deepcopy(model.cfg)\n",
    "\n",
    "# Setup new tokenizer\n",
    "cfg.tokenizer.dir = TOKENIZER_DIR\n",
    "cfg.tokenizer.type = \"bpe\"\n",
    "\n",
    "# Set tokenizer config\n",
    "model.cfg.tokenizer = cfg.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifest_filepath: null\n",
      "sample_rate: 16000\n",
      "batch_size: null\n",
      "shuffle: true\n",
      "num_workers: 8\n",
      "pin_memory: true\n",
      "max_duration: 40\n",
      "min_duration: 0.1\n",
      "is_tarred: true\n",
      "tarred_audio_filepaths: null\n",
      "shuffle_n: 2048\n",
      "bucketing_strategy: fully_randomized\n",
      "bucketing_batch_size: null\n",
      "shard_manifests: true\n",
      "use_lhotse: true\n",
      "use_bucketing: true\n",
      "num_buckets: 30\n",
      "bucket_duration_bins: null\n",
      "batch_duration: 600\n",
      "defer_setup: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "# Setup train/val/test configs\n",
    "print(OmegaConf.to_yaml(cfg.train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train, validation, test configs\n",
    "with open_dict(cfg):\n",
    "  # Train dataset\n",
    "  cfg.train_ds.manifest_filepath = \"DATA/train_manifest.json\"\n",
    "  cfg.train_ds.batch_size = 16\n",
    "  cfg.train_ds.num_workers = 8\n",
    "  cfg.train_ds.pin_memory = True\n",
    "  cfg.train_ds.use_start_end_token = True\n",
    "  cfg.train_ds.trim_silence = True\n",
    "\n",
    "  # Validation dataset\n",
    "  cfg.validation_ds.manifest_filepath = \"DATA/valid_manifest.json\"\n",
    "  cfg.validation_ds.batch_size = 8\n",
    "  cfg.validation_ds.num_workers = 8\n",
    "  cfg.validation_ds.pin_memory = True\n",
    "  cfg.validation_ds.use_start_end_token = True\n",
    "  cfg.validation_ds.trim_silence = True\n",
    "\n",
    "#   # Test dataset\n",
    "#   cfg.test_ds.manifest_filepath = test_manifest_cleaned\n",
    "#   cfg.test_ds.batch_size = 8\n",
    "#   cfg.test_ds.num_workers = 8\n",
    "#   cfg.test_ds.pin_memory = True\n",
    "#   cfg.test_ds.use_start_end_token = True\n",
    "#   cfg.test_ds.trim_silence = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:11:17 dataloader:203] We will be using a Lhotse DataLoader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-13 15:11:17 dataloader:230] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process, possibly impacting the training speed if your tokenizer is very large. If the impact is noticable, set pretokenize=False in dataloader config. (note: that will disable token-per-second filtering and 2D bucketing features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:11:17 dataloader:331] Creating a Lhotse DynamicBucketingSampler (max_batch_duration=600.0 max_batch_size=16)\n",
      "[NeMo I 2025-03-13 15:11:18 collections:197] Dataset loaded with 3635 files totalling 5.11 hours\n",
      "[NeMo I 2025-03-13 15:11:18 collections:198] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "# setup model with new configs\n",
    "model.setup_training_data(cfg.train_ds)\n",
    "model.setup_multiple_validation_data(cfg.validation_ds)\n",
    "# model.setup_multiple_test_data(cfg.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for CTC failures: 2817it [08:43,  5.91it/s]WARNING:root:[Suppressed AudioLoadingError] Error message: The number of declared samples in the recording diverged from the one obtained when loading audio (offset=0.0, duration=6.00515625). This could be internal Lhotse's error or a faulty transform implementation. Please report this issue in Lhotse and show the following: diff=467, audio.shape=(1, 95616), recording=Recording(id='common_voice_bn_31740487', sources=[AudioSource(type='file', channels=[0], source='/home/sami/workspace/nemo-asr-training/DATA/cv-corpus-20.0-2024-12-06/bn/clips/common_voice_bn_31740487.mp3')], sampling_rate=16000, num_samples=96083, duration=6.0051875, channel_ids=[0], transforms=[Resample(source_sampling_rate=32000, target_sampling_rate=16000)])\n",
      "[extra info] When calling: Recording.load_audio(args=(Recording(id='common_voice_bn_31740487', sources=[AudioSource(type='file', channels=[0], source='/home/sami/workspace/nemo-asr-training/DATA/cv-corpus-20.0-2024-12-06/bn/clips/common_voice_bn_31740487.mp3')], sampling_rate=16000, num_samples=96083, duration=6.0051875, channel_ids=[0], transforms=[Resample(source_sampling_rate=32000, target_sampling_rate=16000)]),) kwargs={'channels': 0, 'offset': 0.0, 'duration': 6.00515625})\n",
      "[extra info] When calling: MonoCut.load_audio(args=(MonoCut(id='common_voice_bn_31740487', start=0.0, duration=6.00515625, channel=0, supervisions=[SupervisionSegment(id='common_voice_bn_31740487', recording_id='common_voice_bn_31740487', start=0, duration=6.00515625, channel=0, text='তিনি একটি আরবি ভাষা একাডেমী প্রতিষ্ঠা, আরবি ভাষা বিভাগ স্পনসর।', language=None, speaker=None, gender=None, custom={'tokens': array([102, 179, 159, 150, 817, 937,  46, 937, 971, 938, 948, 965, 758,\n",
      "       937, 979, 159, 150, 817, 937, 228, 167, 868, 942, 949, 939, 966])}, alignment=None)], features=None, recording=Recording(id='common_voice_bn_31740487', sources=[AudioSource(type='file', channels=[0], source='/home/sami/workspace/nemo-asr-training/DATA/cv-corpus-20.0-2024-12-06/bn/clips/common_voice_bn_31740487.mp3')], sampling_rate=16000, num_samples=96083, duration=6.0051875, channel_ids=[0], transforms=[Resample(source_sampling_rate=32000, target_sampling_rate=16000)]), custom={'text': 'তিনি একটি আরবি ভাষা একাডেমী প্রতিষ্ঠা, আরবি ভাষা বিভাগ স্পনসর।', 'dataloading_info': {'rank': 0, 'world_size': 1, 'worker_id': None}}),) kwargs={})\n",
      "[extra info] When calling: MixedCut.load_audio(args=(MixedCut(id='common_voice_bn_31740487', tracks=[MixTrack(cut=MonoCut(id='common_voice_bn_31740487', start=0.0, duration=6.00515625, channel=0, supervisions=[SupervisionSegment(id='common_voice_bn_31740487', recording_id='common_voice_bn_31740487', start=0, duration=6.00515625, channel=0, text='তিনি একটি আরবি ভাষা একাডেমী প্রতিষ্ঠা, আরবি ভাষা বিভাগ স্পনসর।', language=None, speaker=None, gender=None, custom={'tokens': array([102, 179, 159, 150, 817, 937,  46, 937, 971, 938, 948, 965, 758,\n",
      "       937, 979, 159, 150, 817, 937, 228, 167, 868, 942, 949, 939, 966])}, alignment=None)], features=None, recording=Recording(id='common_voice_bn_31740487', sources=[AudioSource(type='file', channels=[0], source='/home/sami/workspace/nemo-asr-training/DATA/cv-corpus-20.0-2024-12-06/bn/clips/common_voice_bn_31740487.mp3')], sampling_rate=16000, num_samples=96083, duration=6.0051875, channel_ids=[0], transforms=[Resample(source_sampling_rate=32000, target_sampling_rate=16000)]), custom={'text': 'তিনি একটি আরবি ভাষা একাডেমী প্রতিষ্ঠা, আরবি ভাষা বিভাগ স্পনসর।', 'dataloading_info': {'rank': 0, 'world_size': 1, 'worker_id': None}}), type='MonoCut', offset=0.0, snr=None), MixTrack(cut=PaddingCut(id='68786cbc-4db7-be08-bed6-1fe3c918c98d', duration=0.69484375, sampling_rate=16000, feat_value=-23.025850929940457, num_frames=None, num_features=None, frame_shift=None, num_samples=11117, video=None, custom=None), type='PaddingCut', offset=6.00515625, snr=None)], transforms=None),) kwargs={})\n",
      "Checking for CTC failures: 7581it [24:20,  5.84it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def analyse_ctc_failures_in_model(model):\n",
    "    count_ctc_failures = 0\n",
    "    am_seq_lengths = []\n",
    "    target_seq_lengths = []\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    mode = model.training\n",
    "\n",
    "    train_dl = model.train_dataloader()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      model = model.eval()\n",
    "      for batch in tqdm(train_dl, desc='Checking for CTC failures'):\n",
    "          x, x_len, y, y_len = batch\n",
    "          x, x_len = x.to(device), x_len.to(device)\n",
    "          x_logprobs, greedy_predictions = model(input_signal=x, input_signal_length=x_len)\n",
    "          # Find how many CTC loss computation failures will occur\n",
    "          for xl, yl in zip(x_len, y_len):\n",
    "              if xl <= yl:\n",
    "                  count_ctc_failures += 1\n",
    "\n",
    "          # Record acoustic model lengths=\n",
    "          am_seq_lengths.extend(x_len.to('cpu').numpy().tolist())\n",
    "\n",
    "          # Record target sequence lengths\n",
    "          target_seq_lengths.extend(y_len.to('cpu').numpy().tolist())\n",
    "\n",
    "          del x, x_len, y, y_len, x_logprobs, greedy_predictions\n",
    "\n",
    "    if mode:\n",
    "      model = model.train()\n",
    "\n",
    "    return count_ctc_failures, am_seq_lengths, target_seq_lengths\n",
    "\n",
    "results = analyse_ctc_failures_in_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ctc_failures, am_seq_lengths, target_seq_lengths = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_ctc_failures > 0:\n",
    "  logging.warning(f\"\\nCTC loss will fail for {num_ctc_failures} samples ({num_ctc_failures * 100./ float(len(am_seq_lengths))} % of samples)!\\n\"\n",
    "                  f\"Increase the vocabulary size of the tokenizer so that this number becomes close to zero !\")\n",
    "else:\n",
    "  logging.info(\"No CTC failure cases !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'am_seq_lengths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute average ratio of T / U\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m avg_T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mam_seq_lengths\u001b[49m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(am_seq_lengths))\n\u001b[1;32m      3\u001b[0m avg_U \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(target_seq_lengths) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target_seq_lengths))\n\u001b[1;32m      5\u001b[0m avg_length_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'am_seq_lengths' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute average ratio of T / U\n",
    "avg_T = sum(am_seq_lengths) / float(len(am_seq_lengths))\n",
    "avg_U = sum(target_seq_lengths) / float(len(target_seq_lengths))\n",
    "\n",
    "avg_length_ratio = 0\n",
    "for am_len, tgt_len in zip(am_seq_lengths, target_seq_lengths):\n",
    "  avg_length_ratio += (am_len / float(tgt_len))\n",
    "avg_length_ratio = avg_length_ratio / len(am_seq_lengths)\n",
    "\n",
    "print(f\"Average Acoustic model sequence length = {avg_T}\")\n",
    "print(f\"Average Target sequence length = {avg_U}\")\n",
    "print()\n",
    "print(f\"Ratio of Average AM sequence length to target sequence length = {avg_length_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: adamw\n",
      "lr: 2.0\n",
      "betas:\n",
      "- 0.9\n",
      "- 0.98\n",
      "weight_decay: 0.001\n",
      "sched:\n",
      "  name: NoamAnnealing\n",
      "  d_model: 512\n",
      "  warmup_steps: 5000\n",
      "  warmup_ratio: null\n",
      "  min_lr: 1.0e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg.optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_dict(model.cfg.optim):\n",
    "  model.cfg.optim.lr = 0.025\n",
    "  model.cfg.optim.weight_decay = 0.001\n",
    "  model.cfg.optim.sched.warmup_steps = None  # Remove default number of steps of warmup\n",
    "  model.cfg.optim.sched.warmup_ratio = 0.10  # 10 % warmup\n",
    "  model.cfg.optim.sched.min_lr = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_dict(model.cfg.spec_augment):\n",
    "  model.cfg.spec_augment.freq_masks = 2\n",
    "  model.cfg.spec_augment.freq_width = 25\n",
    "  model.cfg.spec_augment.time_masks = 10\n",
    "  model.cfg.spec_augment.time_width = 0.05\n",
    "\n",
    "model.spec_augmentation = model.from_config_dict(model.cfg.spec_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wer.use_cer = True\n",
    "model.wer.log_prediction = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning.pytorch as ptl\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  accelerator = 'gpu'\n",
    "else:\n",
    "  accelerator = 'gpu'\n",
    "\n",
    "EPOCHS = 50  # 100 epochs would provide better results\n",
    "\n",
    "trainer = ptl.Trainer(devices=1,\n",
    "                      accelerator=accelerator,\n",
    "                      max_epochs=EPOCHS,\n",
    "                      accumulate_grad_batches=1,\n",
    "                      enable_checkpointing=False,\n",
    "                      logger=False,\n",
    "                      log_every_n_steps=5,\n",
    "                      check_val_every_n_epoch=10)\n",
    "\n",
    "# Setup model with the trainer\n",
    "model.set_trainer(trainer)\n",
    "\n",
    "# finally, update the model's internal config\n",
    "model.cfg = model._cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:12:20 exp_manager:450] ExpManager schema\n",
      "[NeMo I 2025-03-13 15:12:20 exp_manager:451] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False, 'save_last_n_optim_states': -1}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'log_delta_step_timing': False, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0, 'create_straggler_detection_callback': False, 'straggler_detection_params': {'report_time_interval': 300.0, 'calc_relative_gpu_perf': True, 'calc_individual_gpu_perf': True, 'num_gpu_perf_scores_to_log': 5, 'gpu_relative_perf_threshold': 0.7, 'gpu_individual_perf_threshold': 0.7, 'stop_if_detected': False}, 'create_fault_tolerance_callback': False, 'fault_tolerance': {'workload_check_interval': 5.0, 'initial_rank_heartbeat_timeout': 3600.0, 'rank_heartbeat_timeout': 2700.0, 'calculate_timeouts': True, 'safety_factor': 5.0, 'rank_termination_signal': <Signals.SIGKILL: 9>, 'log_level': 'INFO', 'max_rank_restarts': 0, 'max_subsequent_job_failures': 0, 'additional_ft_launcher_args': '', 'simulated_fault': None}, 'log_tflops_per_sec_per_gpu': True}\n",
      "[NeMo I 2025-03-13 15:12:20 exp_manager:509] Experiments will be logged at experiments/lang-bn/ASR-Model-Language-bn/2025-03-13_15-12-20\n",
      "[NeMo I 2025-03-13 15:12:20 exp_manager:1063] TensorboardLogger has been set up\n",
      "[NeMo I 2025-03-13 15:12:20 exp_manager:646] TFLOPs per sec per GPU will be calculated, conditioned on supported models. Defaults to -1 upon failure.\n"
     ]
    }
   ],
   "source": [
    "from nemo.utils import exp_manager\n",
    "import os\n",
    "\n",
    "LANGUAGE = \"bn\"\n",
    "\n",
    "# Environment variable generally used for multi-node multi-gpu training.\n",
    "# In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n",
    "os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "\n",
    "config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=f'experiments/lang-{LANGUAGE}/',\n",
    "    name=f\"ASR-Model-Language-{LANGUAGE}\",\n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor=\"val_wer\",\n",
    "        mode=\"min\",\n",
    "        always_save_nemo=True,\n",
    "        save_best_model=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "config = OmegaConf.structured(config)\n",
    "\n",
    "logdir = exp_manager.exp_manager(trainer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-13 15:12:24 modelPT:793] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.025\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'LhotseSpeechToTextBpeDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:957\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:158\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:138\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates optimizers and schedulers.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    trainer: the Trainer, these optimizers should be connected to\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs \u001b[38;5;241m=\u001b[39m \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:179\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m call\n\u001b[0;32m--> 179\u001b[0m optim_conf \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigure_optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     rank_zero_warn(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    170\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/nemo/core/classes/modelPT.py:870\u001b[0m, in \u001b[0;36mModelPT.configure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconfigure_optimizers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/nemo/core/classes/modelPT.py:797\u001b[0m, in \u001b[0;36mModelPT.setup_optimization\u001b[0;34m(self, optim_config, optim_kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer config = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(optimizer))\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_lr_scheduler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_dl\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Return the optimizer with/without scheduler\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# This return allows multiple optimizers or schedulers to be created\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduler\n",
      "File \u001b[0;32m~/workspace/nemo-asr-training/venv/lib/python3.10/site-packages/nemo/core/optim/lr_scheduler.py:895\u001b[0m, in \u001b[0;36mprepare_lr_scheduler\u001b[0;34m(optimizer, scheduler_config, train_dataloader)\u001b[0m\n\u001b[1;32m    892\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m scheduler_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_num_workers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# Compute effective num max_steps\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;66;03m# TODO: not sure if this will be the correct LR schedule for Megatron\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;66;03m# we may need to override ModelPT setup_optimization\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_dataloader\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'LhotseSpeechToTextBpeDataset' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Finetune Script from nemo repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python speech_to_text_finetune.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
